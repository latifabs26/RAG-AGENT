============================= test session starts =============================
platform win32 -- Python 3.12.1, pytest-8.4.1, pluggy-1.6.0 -- C:\Users\latifa\Downloads\rag-tutorial-v2-main\venv\Scripts\python.exe
cachedir: .pytest_cache
rootdir: C:\Users\latifa\Downloads\rag-tutorial-v2-main
plugins: anyio-4.9.0, langsmith-0.4.8
collecting ... collected 5 items

query_test.py::test_document_pipeline_stages prompt: Human: 
Answer the question based only on the following context:

Document Analysis and Information 
Extraction: A Comprehensive Survey 
Abstract 
This survey provides a comprehensive overview of current approaches, technologies, and challenges 
in document analysis and information extraction systems. We explore the evolution from traditional 
rule-based methods to modern deep learning approaches, with particular focus on document 
understanding, layout analysis, and structured information extraction. The survey examines various 
preprocessing techniques, feature extraction methods, classification algorithms, and post -processing 
strategies used in document analysis pipelines. We also discuss performance evaluation metrics, 
benchmark datasets, and current limitations. Finally, we identify emerging trends and future research

---

ÔùÅ Zero-shot and few-shot learning 
ÔùÅ Self-supervised approaches 
ÔùÅ Cross-modal alignment techniques 
8. Document Classification and Clustering 
8.1 Feature Extraction for Document 
Classification 
ÔùÅ Bag-of-words and TF-IDF 
representations 
ÔùÅ Document embeddings 
ÔùÅ Visual and layout features 
8.2 Classification Algorithms 
ÔùÅ Traditional machine learning 
approaches (SVM, Random Forest) 
ÔùÅ Neural network-based classifiers 
ÔùÅ Hierarchical classification approaches 
8.3 Document Clustering Techniques 
ÔùÅ K-means clustering 
ÔùÅ Hierarchical clustering 
ÔùÅ Density-based clustering 
ÔùÅ Topic modeling approaches (LDA, 
NMF) 
8.4 Performance Evaluation 
ÔùÅ Classification metrics (accuracy, 
precision, recall, F1) 
ÔùÅ Clustering metrics (purity, normalized 
mutual information)

---

ÔùÅ Current era (mid-2010s-present): 
Deep learning approaches enabling 
end-to-end solutions 
2.2 Document Analysis Pipeline 
A typical document analysis pipeline consists 
of: 
ÔùÅ Document acquisition (scanning, 
photographing, digital conversion) 
ÔùÅ Preprocessing (noise removal, 
binarization, deskewing) 
ÔùÅ Layout analysis (segmentation of 
document into regions) 
ÔùÅ OCR (Optical Character Recognition) 
ÔùÅ Information extraction (identifying and 
extracting relevant data) 
ÔùÅ Post-processing (validation, 
normalization, integration) 
2.3 Key Terminology and Concepts 
ÔùÅ OCR (Optical Character Recognition): 
Converting images of text into 
machine-encoded text 
ÔùÅ Document Understanding: 
Comprehending the semantic content 
and structure of documents 
ÔùÅ Layout Analysis: Identifying and

---

and structure of documents 
ÔùÅ Layout Analysis: Identifying and 
classifying regions within a document 
ÔùÅ Information Extraction: Identifying and 
extracting specific pieces of 
information 
ÔùÅ Document Classification: Categorizing 
documents based on their content or 
structure 
ÔùÅ Named Entity Recognition (NER): 
Identifying and classifying named 
entities in text 
3. Document Preprocessing Techniques 
3.1 Image Enhancement 
ÔùÅ Noise reduction techniques 
ÔùÅ Contrast enhancement 
ÔùÅ Binarization methods 
ÔùÅ Skew detection and correction 
ÔùÅ Document image quality assessment 
3.2 Page Segmentation 
ÔùÅ Bottom-up approaches (connected 
component analysis) 
ÔùÅ Top-down approaches (recursive X-Y 
cuts) 
ÔùÅ Hybrid approaches 
ÔùÅ Deep learning-based segmentation 
methods

---

document IE 
ÔùÅ Joint models for entity and relation 
extraction 
6.4 Domain-specific Information Extraction 
ÔùÅ Financial document processing 
(invoices, receipts) 
ÔùÅ Legal document analysis 
ÔùÅ Medical record information extraction 
ÔùÅ Technical documentation processing 
7. Multimodal Approaches for Document 
Understanding 
7.1 Integration of Visual and Textual 
Features 
ÔùÅ Early fusion approaches 
ÔùÅ Late fusion approaches 
ÔùÅ Attention mechanisms for multimodal 
integration 
7.2 Pre-trained Multimodal Models 
ÔùÅ LayoutLM and its variants 
ÔùÅ DocFormer 
ÔùÅ TILT (Text-Image-Layout Transformer) 
ÔùÅ SelfDoc 
7.3 Document Visual Question Answering 
ÔùÅ Document VQA datasets 
ÔùÅ Techniques for answering questions 
about documents 
ÔùÅ Evaluation metrics for document VQA

---

Answer the question based on the above context: How many main stages are mentioned in a typical document analysis pipeline? (Answer with the number only)

Response:  The provided context mentions six main stages in a typical document analysis pipeline.
Sources: ['data\\survey.pdf:0:0', 'data\\survey.pdf:3:0', 'data\\survey.pdf:1:0', 'data\\survey.pdf:1:1', 'data\\survey.pdf:2:2']
PASSED
query_test.py::test_ocr_definition 
Expected Response: 6
Actual Response:  The provided context mentions six main stages in a typical document analysis pipeline.
---
(Answer with 'true' or 'false') Does the actual response match the expected response?

[92mResponse: true[0m
prompt: Human: 
Answer the question based only on the following context:

ÔùÅ Intersection over Union (IoU) for 
region matching 
ÔùÅ Public datasets: FUNSD, DocBank, 
PubLayNet, RVL-CDIP 
ÔùÅ Evaluation protocols and their 
limitations 
5. Optical Character Recognition (OCR) 
5.1 Traditional OCR Approaches 
ÔùÅ Feature extraction techniques 
ÔùÅ Classification methods 
ÔùÅ Commercial OCR engines (ABBYY, 
Tesseract, etc.) 
5.2 Deep Learning-based OCR 
ÔùÅ CNN-based character recognition 
ÔùÅ RNN-based sequence recognition 
ÔùÅ CTC loss function and its application 
in OCR 
ÔùÅ Attention-based sequence-to-
sequence models 
5.3 Post-OCR Processing 
ÔùÅ Error correction techniques 
ÔùÅ Language modeling for OCR 
correction 
ÔùÅ Dictionary-based approaches 
ÔùÅ Context-aware correction methods 
5.4 OCR for Complex Scripts and 
Languages 
ÔùÅ Challenges in non-Latin scripts

---

5.4 OCR for Complex Scripts and 
Languages 
ÔùÅ Challenges in non-Latin scripts 
ÔùÅ Multilingual OCR approaches 
ÔùÅ Script identification techniques 
6. Information Extraction Techniques 
6.1 Rule-based Information Extraction 
ÔùÅ Regular expression-based extraction 
ÔùÅ Template matching approaches 
ÔùÅ Grammar-based methods 
ÔùÅ Limitations of rule-based approaches 
6.2 Machine Learning-based Approaches 
ÔùÅ Hidden Markov Models 
ÔùÅ Conditional Random Fields 
ÔùÅ Support Vector Machines 
ÔùÅ Feature engineering for information 
extraction 
6.3 Deep Learning-based Approaches 
ÔùÅ Named Entity Recognition with 
LSTM/BiLSTM 
ÔùÅ Transformer-based models (BERT, 
RoBERTa, etc.) 
ÔùÅ Graph Convolutional Networks for 
document IE 
ÔùÅ Joint models for entity and relation 
extraction

---

Document Image Processing and OCR 
14. Ye, P., & Doermann, D. (2015). Document 
image quality assessment: A brief survey. 
Journal of Electronic Imaging, 24(2), 020901. 
15. Gatos, B., Pratikakis, I., & Perantonis, S. J. 
(2006). Adaptive degraded document image 
binarization. Pattern Recognition, 39(3), 317-
327. 
16. Breuel, T. M., Ul-Hasan, A., Al-Azawi, M. A., & 
Shafait, F. (2013, August). High-performance 
OCR for printed English and Fraktur using 
LSTM networks. In 12th International 
Conference on Document Analysis and 
Recognition (pp. 683-687). IEEE. 
17. Shi, B., Bai, X., & Yao, C. (2016). An end-to-end 
trainable neural network for image-based 
sequence recognition and its application to 
scene text recognition. IEEE transactions on 
pattern analysis and machine intelligence,

---

ÔùÅ Current era (mid-2010s-present): 
Deep learning approaches enabling 
end-to-end solutions 
2.2 Document Analysis Pipeline 
A typical document analysis pipeline consists 
of: 
ÔùÅ Document acquisition (scanning, 
photographing, digital conversion) 
ÔùÅ Preprocessing (noise removal, 
binarization, deskewing) 
ÔùÅ Layout analysis (segmentation of 
document into regions) 
ÔùÅ OCR (Optical Character Recognition) 
ÔùÅ Information extraction (identifying and 
extracting relevant data) 
ÔùÅ Post-processing (validation, 
normalization, integration) 
2.3 Key Terminology and Concepts 
ÔùÅ OCR (Optical Character Recognition): 
Converting images of text into 
machine-encoded text 
ÔùÅ Document Understanding: 
Comprehending the semantic content 
and structure of documents 
ÔùÅ Layout Analysis: Identifying and

---

layout analysis. In International Conference on 
Document Analysis and Recognition (ICDAR) 
(pp. 1015-1022). IEEE. 
8. Smith, R. (2007, September). An overview of 
the Tesseract OCR engine. In Ninth 
international conference on document analysis 
and recognition (ICDAR 2007) (Vol. 2, pp. 629-
633). IEEE. 
Information Extraction and Named Entity Recognition 
9. Campos, D., Matos, S., & Oliveira, J. L. (2020). 
A survey on named entity recognition: from 
traditional methods to deep learning. ACM 
Computing Surveys, 53(6), 1-28. 
10. Devlin, J., Chang, M. W., Lee, K., & Toutanova, 
K. (2018). BERT: Pre-training of deep 
bidirectional transformers for language 
understanding. In Proceedings of NAACL-HLT 
2019 (pp. 4171-4186). 
11. Li, Y., Zhao, H., Yin, F., & Xu, J. (2019,

---

Answer the question based on the above context: What does OCR stand for? (Answer with the full expansion only)

Response:  Optical Character Recognition stands for Optical Character Recognition.
Sources: ['data\\survey.pdf:2:0', 'data\\survey.pdf:2:1', 'data\\survey.pdf:5:5', 'data\\survey.pdf:1:0', 'data\\survey.pdf:5:3']
PASSED
query_test.py::test_commercial_solutions 
Expected Response: Optical Character Recognition
Actual Response:  Optical Character Recognition stands for Optical Character Recognition.
---
(Answer with 'true' or 'false') Does the actual response match the expected response?

[92mResponse: true[0m
prompt: Human: 
Answer the question based only on the following context:

Document Analysis and Information 
Extraction: A Comprehensive Survey 
Abstract 
This survey provides a comprehensive overview of current approaches, technologies, and challenges 
in document analysis and information extraction systems. We explore the evolution from traditional 
rule-based methods to modern deep learning approaches, with particular focus on document 
understanding, layout analysis, and structured information extraction. The survey examines various 
preprocessing techniques, feature extraction methods, classification algorithms, and post -processing 
strategies used in document analysis pipelines. We also discuss performance evaluation metrics, 
benchmark datasets, and current limitations. Finally, we identify emerging trends and future research

---

directions in this rapidly evolving field. This survey serves as a foundation for the ExaQ project, which 
aims to develop an advanced document analysis and information extraction system for handling 
diverse document types. 
1. Introduction 
1.1 Motivation and Significance 
Document analysis and information extraction 
have become increasingly important in various 
domains including business, healthcare, legal, 
and administrative sectors. Organizations face 
challenges in efficiently processing the vast 
amounts of documents they receive, extracting 
relevant information, and integrating this data 
into their workflows. Manual processing is 
time-consuming, error-prone, and costly, 
driving the need for automated solutions. 
1.2 Scope and Objectives 
This survey aims to:

---

1.2 Scope and Objectives 
This survey aims to: 
ÔùÅ Provide a comprehensive overview of 
document analysis and information 
extraction techniques 
ÔùÅ Classify existing approaches based on 
their methodologies and applications 
ÔùÅ Identify current challenges and 
limitations in the field 
ÔùÅ Explore emerging trends and future 
research directions 
1.3 Document Types and Challenges 
We consider various document types 
including: 
ÔùÅ Structured documents (forms, 
invoices, receipts) 
ÔùÅ Semi-structured documents (reports, 
technical documentation) 
ÔùÅ Unstructured documents (letters, 
emails) 
ÔùÅ Document images with varying quality, 
layout, and format 
Key challenges include handling document 
variability, maintaining accuracy across 
diverse document types, managing complex

---

ÔùÅ Research directions based on survey 
findings 
15. Conclusion 
This survey has provided a comprehensive 
overview of document analysis and information 
extraction techniques, covering traditional 
approaches through to state-of-the-art deep 
learning methods. We have identified current 
challenges, emerging trends, and promising 
research directions. The field continues to 
evolve rapidly, driven by advances in machine 
learning and the increasing need for 
automated document processing solutions 
across various domains. The ExaQ project 
builds upon these foundations while 
addressing specific gaps identified in existing 
approaches, particularly in handling diverse 
document types with varying structures and 
quality. 
 
 
References 
Core Document Analysis and Understanding

---

ÔùÅ Clustering metrics (purity, normalized 
mutual information) 
ÔùÅ Benchmark datasets for document 
classification 
9. End-to-End Document Understanding 
Systems 
9.1 Commercial Solutions 
ÔùÅ Microsoft Azure Form Recognizer 
ÔùÅ Google Document AI 
ÔùÅ Amazon Textract 
ÔùÅ ABBYY FlexiCapture 
9.2 Open-Source Frameworks 
ÔùÅ Tesseract OCR 
ÔùÅ Apache Tika 
ÔùÅ DocTR 
ÔùÅ Layout Parser 
9.3 Integration and Workflow Automation 
ÔùÅ Document processing pipelines 
ÔùÅ Business process automation 
ÔùÅ Document management systems 
integration 
9.4 Comparative Analysis 
ÔùÅ Performance comparison across 
systems 
ÔùÅ Feature comparison 
ÔùÅ Domain adaptability 
ÔùÅ Scalability and deployment 
considerations 
10. Ethical and Privacy Considerations 
10.1 Privacy Concerns in Document 
Processing 
ÔùÅ Handling sensitive information

---

Answer the question based on the above context: Which Microsoft service is mentioned as a commercial document analysis solution? (Answer with the service name only)

Response:  Microsoft Azure Form Recognizer
Sources: ['data\\survey.pdf:0:0', 'data\\survey.pdf:0:1', 'data\\survey.pdf:0:2', 'data\\survey.pdf:5:0', 'data\\survey.pdf:3:1']
PASSED
query_test.py::test_exaq_project 
Expected Response: Microsoft Azure Form Recognizer
Actual Response:  Microsoft Azure Form Recognizer
---
(Answer with 'true' or 'false') Does the actual response match the expected response?

[92mResponse: true[0m
prompt: Human: 
Answer the question based only on the following context:

ÔùÅ Research directions based on survey 
findings 
15. Conclusion 
This survey has provided a comprehensive 
overview of document analysis and information 
extraction techniques, covering traditional 
approaches through to state-of-the-art deep 
learning methods. We have identified current 
challenges, emerging trends, and promising 
research directions. The field continues to 
evolve rapidly, driven by advances in machine 
learning and the increasing need for 
automated document processing solutions 
across various domains. The ExaQ project 
builds upon these foundations while 
addressing specific gaps identified in existing 
approaches, particularly in handling diverse 
document types with varying structures and 
quality. 
 
 
References 
Core Document Analysis and Understanding

---

directions in this rapidly evolving field. This survey serves as a foundation for the ExaQ project, which 
aims to develop an advanced document analysis and information extraction system for handling 
diverse document types. 
1. Introduction 
1.1 Motivation and Significance 
Document analysis and information extraction 
have become increasingly important in various 
domains including business, healthcare, legal, 
and administrative sectors. Organizations face 
challenges in efficiently processing the vast 
amounts of documents they receive, extracting 
relevant information, and integrating this data 
into their workflows. Manual processing is 
time-consuming, error-prone, and costly, 
driving the need for automated solutions. 
1.2 Scope and Objectives 
This survey aims to:

---

1.2 Scope and Objectives 
This survey aims to: 
ÔùÅ Provide a comprehensive overview of 
document analysis and information 
extraction techniques 
ÔùÅ Classify existing approaches based on 
their methodologies and applications 
ÔùÅ Identify current challenges and 
limitations in the field 
ÔùÅ Explore emerging trends and future 
research directions 
1.3 Document Types and Challenges 
We consider various document types 
including: 
ÔùÅ Structured documents (forms, 
invoices, receipts) 
ÔùÅ Semi-structured documents (reports, 
technical documentation) 
ÔùÅ Unstructured documents (letters, 
emails) 
ÔùÅ Document images with varying quality, 
layout, and format 
Key challenges include handling document 
variability, maintaining accuracy across 
diverse document types, managing complex

---

Document Analysis and Information 
Extraction: A Comprehensive Survey 
Abstract 
This survey provides a comprehensive overview of current approaches, technologies, and challenges 
in document analysis and information extraction systems. We explore the evolution from traditional 
rule-based methods to modern deep learning approaches, with particular focus on document 
understanding, layout analysis, and structured information extraction. The survey examines various 
preprocessing techniques, feature extraction methods, classification algorithms, and post -processing 
strategies used in document analysis pipelines. We also discuss performance evaluation metrics, 
benchmark datasets, and current limitations. Finally, we identify emerging trends and future research

---

ÔùÅ Zero-shot and few-shot learning 
ÔùÅ Self-supervised approaches 
ÔùÅ Cross-modal alignment techniques 
8. Document Classification and Clustering 
8.1 Feature Extraction for Document 
Classification 
ÔùÅ Bag-of-words and TF-IDF 
representations 
ÔùÅ Document embeddings 
ÔùÅ Visual and layout features 
8.2 Classification Algorithms 
ÔùÅ Traditional machine learning 
approaches (SVM, Random Forest) 
ÔùÅ Neural network-based classifiers 
ÔùÅ Hierarchical classification approaches 
8.3 Document Clustering Techniques 
ÔùÅ K-means clustering 
ÔùÅ Hierarchical clustering 
ÔùÅ Density-based clustering 
ÔùÅ Topic modeling approaches (LDA, 
NMF) 
8.4 Performance Evaluation 
ÔùÅ Classification metrics (accuracy, 
precision, recall, F1) 
ÔùÅ Clustering metrics (purity, normalized 
mutual information)

---

Answer the question based on the above context: What is the name of the project that this survey serves as a foundation for? (Answer with the project name only)

Response:  ExaQ
Sources: ['data\\survey.pdf:5:0', 'data\\survey.pdf:0:1', 'data\\survey.pdf:0:2', 'data\\survey.pdf:0:0', 'data\\survey.pdf:3:0']
PASSED
query_test.py::test_document_types 
Expected Response: ExaQ
Actual Response:  ExaQ
---
(Answer with 'true' or 'false') Does the actual response match the expected response?

[92mResponse: true[0m
prompt: Human: 
Answer the question based only on the following context:

1.2 Scope and Objectives 
This survey aims to: 
ÔùÅ Provide a comprehensive overview of 
document analysis and information 
extraction techniques 
ÔùÅ Classify existing approaches based on 
their methodologies and applications 
ÔùÅ Identify current challenges and 
limitations in the field 
ÔùÅ Explore emerging trends and future 
research directions 
1.3 Document Types and Challenges 
We consider various document types 
including: 
ÔùÅ Structured documents (forms, 
invoices, receipts) 
ÔùÅ Semi-structured documents (reports, 
technical documentation) 
ÔùÅ Unstructured documents (letters, 
emails) 
ÔùÅ Document images with varying quality, 
layout, and format 
Key challenges include handling document 
variability, maintaining accuracy across 
diverse document types, managing complex

---

document IE 
ÔùÅ Joint models for entity and relation 
extraction 
6.4 Domain-specific Information Extraction 
ÔùÅ Financial document processing 
(invoices, receipts) 
ÔùÅ Legal document analysis 
ÔùÅ Medical record information extraction 
ÔùÅ Technical documentation processing 
7. Multimodal Approaches for Document 
Understanding 
7.1 Integration of Visual and Textual 
Features 
ÔùÅ Early fusion approaches 
ÔùÅ Late fusion approaches 
ÔùÅ Attention mechanisms for multimodal 
integration 
7.2 Pre-trained Multimodal Models 
ÔùÅ LayoutLM and its variants 
ÔùÅ DocFormer 
ÔùÅ TILT (Text-Image-Layout Transformer) 
ÔùÅ SelfDoc 
7.3 Document Visual Question Answering 
ÔùÅ Document VQA datasets 
ÔùÅ Techniques for answering questions 
about documents 
ÔùÅ Evaluation metrics for document VQA

---

about documents 
ÔùÅ Evaluation metrics for document VQA 
7.4 Future Directions in Multimodal 
Document Understanding

---

and structure of documents 
ÔùÅ Layout Analysis: Identifying and 
classifying regions within a document 
ÔùÅ Information Extraction: Identifying and 
extracting specific pieces of 
information 
ÔùÅ Document Classification: Categorizing 
documents based on their content or 
structure 
ÔùÅ Named Entity Recognition (NER): 
Identifying and classifying named 
entities in text 
3. Document Preprocessing Techniques 
3.1 Image Enhancement 
ÔùÅ Noise reduction techniques 
ÔùÅ Contrast enhancement 
ÔùÅ Binarization methods 
ÔùÅ Skew detection and correction 
ÔùÅ Document image quality assessment 
3.2 Page Segmentation 
ÔùÅ Bottom-up approaches (connected 
component analysis) 
ÔùÅ Top-down approaches (recursive X-Y 
cuts) 
ÔùÅ Hybrid approaches 
ÔùÅ Deep learning-based segmentation 
methods

---

extraction 
12.3 Interactive Document Processing 
ÔùÅ Human-in-the-loop approaches 
ÔùÅ Active learning for document analysis 
ÔùÅ Continuous learning and adaptation 
12.4 Multimodal and Cross-modal Learning 
ÔùÅ Integration of text, layout, and visual 
information 
ÔùÅ Cross-modal representation learning 
ÔùÅ Document-level understanding 
13. Application Domains 
13.1 Financial Services 
ÔùÅ Invoice processing 
ÔùÅ Receipt analysis 
ÔùÅ Financial statement analysis 
ÔùÅ KYC document verification 
13.2 Healthcare 
ÔùÅ Medical record processing 
ÔùÅ Clinical document understanding 
ÔùÅ Healthcare form processing 
ÔùÅ Prescription analysis 
13.3 Legal Domain 
ÔùÅ Contract analysis 
ÔùÅ Legal document classification 
ÔùÅ Compliance document processing 
ÔùÅ Case document analysis 
13.4 Government and Administrative

---

Answer the question based on the above context: What type of documents includes forms, invoices, and receipts according to section 1.3? (Answer with one word only)

Response:  Structured
Sources: ['data\\survey.pdf:0:2', 'data\\survey.pdf:2:2', 'data\\survey.pdf:2:3', 'data\\survey.pdf:1:1', 'data\\survey.pdf:4:1']
PASSED
Expected Response: Structured
Actual Response:  Structured
---
(Answer with 'true' or 'false') Does the actual response match the expected response?

[92mResponse: true[0m


============================== warnings summary ===============================
query_data.py:2
  C:\Users\latifa\Downloads\rag-tutorial-v2-main\query_data.py:2: LangChainDeprecationWarning: Importing Chroma from langchain.vectorstores is deprecated. Please replace deprecated imports:
  
  >> from langchain.vectorstores import Chroma
  
  with new imports of:
  
  >> from langchain_community.vectorstores import Chroma
  You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
    from langchain.vectorstores import Chroma

query_test.py::test_document_pipeline_stages
  C:\Users\latifa\Downloads\rag-tutorial-v2-main\get_embedding_function.py:9: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.
    embeddings = OllamaEmbeddings(model="nomic-embed-text")

query_test.py::test_document_pipeline_stages
  C:\Users\latifa\Downloads\rag-tutorial-v2-main\query_data.py:36: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.
    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)

query_test.py::test_document_pipeline_stages
  C:\Users\latifa\Downloads\rag-tutorial-v2-main\query_data.py:46: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.
    model = Ollama(model="mistral")     # or llama3.2:3b plus leger

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
================== 5 passed, 4 warnings in 79.71s (0:01:19) ===================
